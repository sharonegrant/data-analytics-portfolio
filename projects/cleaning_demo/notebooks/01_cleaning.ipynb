{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a27294-93e7-4c54-ba60-9e1660fe6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (1280, 15)\n",
      "After de-duplication: (1200, 15)\n",
      "Cleaned shape: (1200, 18)\n",
      "Saved cleaned dataset to: ../../../outputs/data/cleaning_demo/customer_lifecycle_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:32: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:32: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:32: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dedup[\"customer_age_days\"] = (reference_date - df_dedup[\"signup_date\"]).dt.days\n",
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dedup[\"is_active_90d\"] = df_dedup[\"days_since_last_purchase\"] <= 90\n",
      "/var/folders/5v/5z1dw78974g093k15vck26lm0000gn/T/ipykernel_6965/2369186487.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dedup[\"revenue_band\"] = df_dedup[\"total_revenue\"].apply(revenue_band)\n"
     ]
    }
   ],
   "source": [
    "# Customer lifecycle cleaning demo\n",
    "# --------------------------------\n",
    "# Goal: take a messy customer-level lifecycle & revenue export and turn it into\n",
    "# an analysis-ready table a senior leader could use for LTV, churn, and segmentation work.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1. Paths & data load\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "RAW_PATH = \"../../../data/cleaning_demo/customer_lifecycle_raw.csv\"\n",
    "OUTPUT_DIR = \"../../../outputs/data/cleaning_demo\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, \"customer_lifecycle_cleaned.csv\")\n",
    "\n",
    "df_raw = pd.read_csv(RAW_PATH)\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()\n",
    "\n",
    "# Work on a copy so we can always refer back to df_raw if needed\n",
    "df = df_raw.copy()\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2. Parse dates & fix basic types\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "date_cols = [\"signup_date\", \"first_purchase_date\", \"last_purchase_date\"]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "numeric_cols = [\n",
    "    \"total_revenue\",\n",
    "    \"num_orders\",\n",
    "    \"avg_order_value\",\n",
    "    \"days_since_last_purchase\",\n",
    "    \"nps_last_6mo\",\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3. Standardize categorical fields\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def normalize_channel(x):\n",
    "    if pd.isna(x) or str(x).strip() == \"\":\n",
    "        return np.nan\n",
    "    t = str(x).strip().lower()\n",
    "    if \"paid\" in t or \"ppc\" in t:\n",
    "        return \"Paid Search\"\n",
    "    if \"organic\" in t or \"seo\" in t or \"org \" in t:\n",
    "        return \"Organic\"\n",
    "    if \"email\" in t or \"eml\" in t:\n",
    "        return \"Email\"\n",
    "    if \"ref\" in t:\n",
    "        return \"Referral\"\n",
    "    if \"social\" in t or \"fb\" in t or \"ig\" in t:\n",
    "        return \"Social\"\n",
    "    return \"Other\"\n",
    "\n",
    "def normalize_region(x):\n",
    "    if pd.isna(x) or str(x).strip() == \"\":\n",
    "        return np.nan\n",
    "    t = str(x).strip().lower()\n",
    "    if \"north\" in t or t in {\"ne\", \"n.e.\"}:\n",
    "        return \"Northeast\"\n",
    "    if \"mid\" in t or \"mw\" in t:\n",
    "        return \"Midwest\"\n",
    "    if \"south\" in t or \"se/\" in t or \"sw\" in t:\n",
    "        return \"South\"\n",
    "    if \"west\" in t or t in {\"w.\", \"pac west\"}:\n",
    "        return \"West\"\n",
    "    return \"Other\"\n",
    "\n",
    "def normalize_tier(x):\n",
    "    if pd.isna(x) or str(x).strip() == \"\":\n",
    "        return \"None\"\n",
    "    t = str(x).strip().lower()\n",
    "    if t.startswith(\"gold\") or t == \"gld\":\n",
    "        return \"Gold\"\n",
    "    if t.startswith(\"silver\") or t == \"slvr\":\n",
    "        return \"Silver\"\n",
    "    if t.startswith(\"bronze\") or t == \"brz\" or t == \"brnze\":\n",
    "        return \"Bronze\"\n",
    "    if t in {\"none\", \"na\"}:\n",
    "        return \"None\"\n",
    "    return \"None\"\n",
    "\n",
    "def normalize_opt_in(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    t = str(x).strip().lower()\n",
    "    if t in {\"true\", \"y\", \"yes\", \"1\"}:\n",
    "        return True\n",
    "    if t in {\"false\", \"n\", \"no\", \"0\", \"\"}:\n",
    "        return False\n",
    "    return np.nan\n",
    "\n",
    "def normalize_status(x):\n",
    "    if pd.isna(x) or str(x).strip() == \"\":\n",
    "        return np.nan\n",
    "    t = str(x).strip().lower()\n",
    "    if t in {\"active\", \"act\", \"current\"}:\n",
    "        return \"Active\"\n",
    "    if \"churn\" in t or t in {\"lost\", \"chrn\"}:\n",
    "        return \"Churned\"\n",
    "    if \"risk\" in t:\n",
    "        return \"At Risk\"\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"acquisition_channel\"] = df[\"acquisition_channel\"].apply(normalize_channel)\n",
    "df[\"region\"] = df[\"region\"].apply(normalize_region)\n",
    "df[\"membership_tier\"] = df[\"membership_tier\"].apply(normalize_tier)\n",
    "df[\"email_opt_in\"] = df[\"email_opt_in\"].apply(normalize_opt_in)\n",
    "df[\"status\"] = df[\"status\"].apply(normalize_status)\n",
    "\n",
    "# Strip whitespace from industry labels and standardize capitalization\n",
    "df[\"industry\"] = (\n",
    "    df[\"industry\"]\n",
    "    .astype(\"string\")\n",
    "    .str.strip()\n",
    "    .replace(\"\", pd.NA)\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4. Handle numeric anomalies (revenue, NPS, days since last purchase)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Negative revenue is almost always a data error in this context -> set to NaN\n",
    "df[\"total_revenue\"] = df[\"total_revenue\"].where(df[\"total_revenue\"] >= 0, np.nan)\n",
    "\n",
    "# Recalculate avg_order_value from cleaned revenue & num_orders\n",
    "df[\"avg_order_value\"] = df[\"total_revenue\"] / df[\"num_orders\"]\n",
    "\n",
    "# Valid NPS scores are 0–10; treat anything else (11, 12, 99, etc.) as missing\n",
    "df[\"nps_last_6mo\"] = df[\"nps_last_6mo\"].where(\n",
    "    df[\"nps_last_6mo\"].between(0, 10), np.nan\n",
    ")\n",
    "\n",
    "# Recalculate days_since_last_purchase from last_purchase_date for consistency\n",
    "reference_date = pd.to_datetime(\"2024-01-01\")\n",
    "df[\"days_since_last_purchase\"] = (\n",
    "    (reference_date - df[\"last_purchase_date\"]).dt.days\n",
    ")\n",
    "df.loc[df[\"last_purchase_date\"].isna(), \"days_since_last_purchase\"] = np.nan\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 5. Deduplicate customers\n",
    "# --------------------------------------------------------------------\n",
    "# In the raw export, some customers appear multiple times.\n",
    "# We keep the most recent, highest-revenue record per customer_id.\n",
    "\n",
    "df_sorted = df.sort_values(\n",
    "    by=[\"customer_id\", \"last_purchase_date\", \"total_revenue\"],\n",
    "    ascending=[True, False, False],\n",
    ")\n",
    "\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"customer_id\", keep=\"first\")\n",
    "print(\"After de-duplication:\", df_dedup.shape)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 6. Derive business-friendly fields\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Customer \"age\" in days since signup\n",
    "df_dedup[\"customer_age_days\"] = (reference_date - df_dedup[\"signup_date\"]).dt.days\n",
    "\n",
    "# Flag: recently active (e.g., purchased in last 90 days)\n",
    "df_dedup[\"is_active_90d\"] = df_dedup[\"days_since_last_purchase\"] <= 90\n",
    "\n",
    "# Simple revenue banding for segmentation\n",
    "def revenue_band(x):\n",
    "    if pd.isna(x):\n",
    "        return \"Unknown\"\n",
    "    if x < 500:\n",
    "        return \"< $500\"\n",
    "    if x < 2000:\n",
    "        return \"$500–$2k\"\n",
    "    if x < 5000:\n",
    "        return \"$2k–$5k\"\n",
    "    if x < 10000:\n",
    "        return \"$5k–$10k\"\n",
    "    return \">$10k\"\n",
    "\n",
    "df_dedup[\"revenue_band\"] = df_dedup[\"total_revenue\"].apply(revenue_band)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 7. Final column ordering & save\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "cols_order = [\n",
    "    \"customer_id\",\n",
    "    \"signup_date\",\n",
    "    \"first_purchase_date\",\n",
    "    \"last_purchase_date\",\n",
    "    \"customer_age_days\",\n",
    "    \"days_since_last_purchase\",\n",
    "    \"is_active_90d\",\n",
    "    \"status\",\n",
    "    \"acquisition_channel\",\n",
    "    \"region\",\n",
    "    \"industry\",\n",
    "    \"membership_tier\",\n",
    "    \"email_opt_in\",\n",
    "    \"num_orders\",\n",
    "    \"total_revenue\",\n",
    "    \"avg_order_value\",\n",
    "    \"revenue_band\",\n",
    "    \"nps_last_6mo\",\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist (defensive)\n",
    "cols_order = [c for c in cols_order if c in df_dedup.columns]\n",
    "df_clean = df_dedup[cols_order].copy()\n",
    "\n",
    "print(\"Cleaned shape:\", df_clean.shape)\n",
    "df_clean.head()\n",
    "\n",
    "df_clean.to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"Saved cleaned dataset to:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77afaf63-e635-4706-a54c-bb9cadd5aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharongrant/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/sharongrant/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  70%|████████████████████▊         | 16/23 [00:00<00:00, 127.32it/s, Describe variable: nps_last_6mo]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 449389.71it/s]\u001b[A\n",
      "Summarize dataset: 100%|█████████████████████████████████████████████████████| 77/77 [00:01<00:00, 40.46it/s, Completed]\n",
      "Generate report structure: 100%|██████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Render HTML: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.32it/s]\n",
      "Export report to file: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 551.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved profile report to: ../../../docs/cleaning_demo/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "\n",
    "# Create a profiling report on the cleaned dataset\n",
    "profile = ProfileReport(\n",
    "    df_clean,\n",
    "    title=\"Customer Lifecycle – Cleaning Demo\",\n",
    "    explorative=True\n",
    ")\n",
    "\n",
    "report_dir = \"../../../docs/cleaning_demo\"\n",
    "os.makedirs(report_dir, exist_ok=True)\n",
    "report_path = os.path.join(report_dir, \"index.html\")\n",
    "\n",
    "profile.to_file(report_path)\n",
    "print(\"Saved profile report to:\", report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d379d3-12a0-47db-9877-25024b492a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
